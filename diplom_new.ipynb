{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e118ce7-b2f9-407a-a4cd-d6e0e44b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739fcd83-c328-4184-ba63-16156988e53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>split</th>\n",
       "      <th>live_or_spoof</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Data/train/1/live/000184.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Data/train/1/live/032887.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Data/train/1/live/059151.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Data/train/1/live/072342.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Data/train/1/live/072393.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            path  split live_or_spoof  class_label\n",
       "0  /Data/train/1/live/000184.jpg  train          live          0.0\n",
       "1  /Data/train/1/live/032887.jpg  train          live          0.0\n",
       "2  /Data/train/1/live/059151.jpg  train          live          0.0\n",
       "3  /Data/train/1/live/072342.jpg  train          live          0.0\n",
       "4  /Data/train/1/live/072393.jpg  train          live          0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('seleb_non_none.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02566fd-5d27-4f7a-8023-ac69a4afc6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>split</th>\n",
       "      <th>live_or_spoof</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1/live/000184.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/1/live/032887.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/1/live/059151.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/1/live/072342.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/1/live/072393.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path  split live_or_spoof  class_label\n",
       "0  train/1/live/000184.jpg  train          live          0.0\n",
       "1  train/1/live/032887.jpg  train          live          0.0\n",
       "2  train/1/live/059151.jpg  train          live          0.0\n",
       "3  train/1/live/072342.jpg  train          live          0.0\n",
       "4  train/1/live/072393.jpg  train          live          0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['path'] = data['path'].apply(lambda x: x.replace('/Data/', ''))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14185e3-4907-4bd5-9f80-a452cdbf16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm import create_model\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1040b881-4894-4af1-8c73-9911a274e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Формируем полный путь к изображению\n",
    "        img_path = os.path.join(self.root_dir, self.dataframe.iloc[idx]['path'])\n",
    "        \n",
    "        # Проверяем существование файла\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Файл не найден: {img_path}\")\n",
    "        \n",
    "        # Загружаем метки\n",
    "        live_or_spoof = 1 if self.dataframe.iloc[idx]['live_or_spoof'] == 'live' else 0  \n",
    "        class_label = self.dataframe.iloc[idx]['class_label']  \n",
    "        \n",
    "        # Открываем изображение\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Применяем преобразования\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, live_or_spoof, class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad38d45-000f-4a15-b4b6-68fc70fb694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Изменяем размер изображений\n",
    "    transforms.ToTensor(),         # Преобразуем в тензор\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Нормализация\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcd9557-1732-4a23-a340-ce10a0c21f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/annam/Documents/Проекты/Диплом/Данные 2/CelebA_Spoof/Data\"\n",
    "\n",
    "train_df = data[data['path'].str.contains('train')]\n",
    "test_df = data[data['path'].str.contains('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a10c5ab-0504-4d2a-9e6a-6f2c8300bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем датасеты\n",
    "train_dataset = CustomDataset(train_df, root_dir=data_dir, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, root_dir=data_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbc090b-ec30-4ad4-8fa2-467dbb0c804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"mobilevitv2_175\", pretrained=True)\n",
    "\n",
    "in_features = model.head.in_features \n",
    "model.head = nn.Identity()  \n",
    "\n",
    "model.global_pool = nn.AdaptiveAvgPool2d((1, 1))  \n",
    "\n",
    "# два отдельных выхода\n",
    "model.fc_live_or_spoof = nn.Linear(in_features, 2)  \n",
    "model.fc_class_label = nn.Linear(in_features, 10) \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6619da9e-564e-42b9-9ec6-ab8662c59681",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bin = nn.CrossEntropyLoss()  \n",
    "criterion_multi = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b11524-fd9d-48ac-ac6c-ac9fa738cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, criterion_bin, criterion_multi, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, live_or_spoof, class_labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            live_or_spoof = live_or_spoof.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            features = model(images)  \n",
    "            features = model.global_pool(features)  \n",
    "            features = features.view(features.size(0), -1)  \n",
    "            outputs_bin = model.fc_live_or_spoof(features)  \n",
    "            outputs_multi = model.fc_class_label(features)  \n",
    "            \n",
    "            loss_bin = criterion_bin(outputs_bin, live_or_spoof)\n",
    "            loss_multi = criterion_multi(outputs_multi, class_labels)\n",
    "            loss = loss_bin + loss_multi\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Эпоха {epoch+1}/{num_epochs}, Потеря: {running_loss / len(dataloader)}\")\n",
    "    return model\n",
    "\n",
    "# Обучение модели\n",
    "model = train_model(model, train_loader, criterion_bin, criterion_multi, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fe730-65a9-4fde-8068-e8900f108541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c49bd8-c2ac-471d-96df-a1333d7efee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee2881-f3ec-4a93-b84b-20efd77933e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33b354-acad-49b0-bd57-1f2f3e79239a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
